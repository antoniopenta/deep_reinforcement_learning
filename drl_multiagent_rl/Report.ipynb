{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaboration and Competition Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](https://user-images.githubusercontent.com/10624937/42135623-e770e354-7d12-11e8-998d-29fc74429ca2.gif)\n",
    "\n",
    "- More info about the purpose of the project can be read here : [Udacity Project link](https://github.com/udacity/deep-reinforcement-learning/tree/master/p3_collab-compet)\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Create a python env as described here: https://github.com/udacity/deep-reinforcement-learning/tree/master/python\n",
    "\n",
    "- Download the project structure here : [github](https://github.com/antoniopenta/deep_reinforcement_learning/tree/master/drl_multiagent_rl)\n",
    "\n",
    "\n",
    "- You need to download the unity env Tennis at the following link (Mac) and save it (unzipped) in the env folder of the main project: https://s3-us-west-1.amazonaws.com/udacity-drlnd/P3/Tennis/Tennis.app.zip\n",
    "\n",
    "\n",
    "- **AWS configuration**, the code has been runned on the AWS instance using GPU.\n",
    "    - To AWS instance (p2.xlarge) is the Deep Learning AMI with Source Code (CUDA 8, Ubuntu) (you can search it on the AWS Marketplace). I have used the credit from the Udacity course.\n",
    "    -  The configuration is well explained in the extra curriculm activities (you can find notes with more details in aws.txt file saved within this repository).\n",
    "\n",
    "- For AWS, the unity env can be downloaded [here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P3/Tennis/Tennis_Linux_NoVis.zip), You will not be able to watch the agent without enabling a virtual screen, but you will be able to train the agent.\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Structure\n",
    "\n",
    "- The project has these foldes:\n",
    "    - **data**: it contains data that are created during the execution\n",
    "    - **framework**: it contain the code for the networks,agent,and cordinator \n",
    "    - **env**: where the unity env is store\n",
    "    - **model**: where the checkpoint for the network is saved\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "This project uses **Tennis** Unity environment. \n",
    "\n",
    "- In this environment, two agents control rackets to bounce a ball over a net. \n",
    "- If an agent hits the ball over the net, it receives a reward of +0.1. \n",
    "- If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.\n",
    "- Thus, the goal of each agent is to keep the ball in play.\n",
    "- The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. - - Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the main approach\n",
    "- The code algorithm is Deep Deterministic Policy Gradient (DDPG), which is based on the Policy Gradient approach.\n",
    "- The core idea of the algorithm is described in the Udacity videos [video1](https://youtu.be/0NVOPIyrr98) [video2](https://youtu.be/RT-HDnAVe9o)\n",
    "- The algorithm is using the Actor-Critic approach. \n",
    "- The Actor is a Neural Network that approximates a deterministic policy. It takes in input the state and the output is an array of values, one for each action.\n",
    "- The Actor is used to approximate the policy ($\\pi(a\\mid s;\\theta_\\pi)$).\n",
    "- In DDPG, the output is deterministic, and it represents the policy value the action space. The outputs are values in the range [-1,1]\n",
    "- The Critic is used to give feedback about the value of the input state observed by the actor and the action considered in the actor.\n",
    "- Both Actor and Critic have a target and regular networks. The target network is used to define the desired target, avoiding to have the same network for considering the prediction and the target. This is the same idea used in the DQN algorithm.\n",
    "- In the DDPG algorithm, there is a soft update approach, which means that the target network is updated more often but with a smaller change.\n",
    "- The DDPG is a policy gradient algorithm, this kind of algorithms suffers from having large variance, due to their Monte Carlo approach in computing the cumulative reword.\n",
    "- To reduce the variance, a Temporal Difference approach is used together with bootstrapping, this approach reduces the variance but introduce a bias.\n",
    "- The exploration of the action space is done by injecting the noise in the last layer of the Actor Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Explanation\n",
    "\n",
    "- A list of agents is created, the agents share the critic network (main_script_maddpg_train.py)\n",
    "- The network stucture is defiend in network.py\n",
    "- The agent functions are defined in the class **class DDPGAgent()** in agent.py\n",
    "- A coordinator is used to send tasks to the agents (**class MADDPGCoordinator()** in coordinator.py)\n",
    "- This is the main loop for the training in main_script_maddpg_train.py:\n",
    "\n",
    "```python\n",
    "    for i_episode in range(0, config.num_episodes):\n",
    "\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        # get the observation\n",
    "        states = env_info.vector_observations\n",
    "        # reset the noise of each agent\n",
    "        maddpg.reset_noise()\n",
    "        # used to store results\n",
    "        scores = np.zeros(num_agents)\n",
    "\n",
    "        for t_step in range(config.max_steps_4_episodes):\n",
    "\n",
    "            # get the actions from the agent using their local network\n",
    "            actions = maddpg.agents_act(states, exploration=exploration_eps)\n",
    "            #run the actions\n",
    "            env_info = env.step(actions)[brain_name]  # send the action to the environment\n",
    "            #get the result\n",
    "            next_states = env_info.vector_observations  # get the next state\n",
    "            rewards = env_info.rewards  # get the reward\n",
    "            dones = env_info.local_done\n",
    "            #save the result in the buffer\n",
    "            maddpg.remember(states, actions, rewards, next_states, dones)\n",
    "            #make a step\n",
    "            maddpg.step(t_step)\n",
    "            # update sarsa\n",
    "            states = next_states\n",
    "            scores += rewards\n",
    "            # reduce explortion\n",
    "            exploration_eps = exploration_strategy_1(exploration_eps, config)\n",
    "\n",
    "            if np.any(dones):\n",
    "                break\n",
    "\n",
    "\n",
    "        score = np.max(scores)\n",
    "```\n",
    "- **Comments**:\n",
    "\n",
    "    - the **exploration_strategy_1(exploration_eps, config)** uses a decay of the exploration eps starting from 2 until 0.05, the parameters are in the config class.\n",
    "    - the **maddpg.remember(states, actions, rewards, next_states, dones)** stores the sarsa observations in the central buffer.\n",
    "    - the learning (if conditions are satisfied) is done in **maddpg.step(t_step)**.\n",
    "    - the noise can be injected in the action prediction from the network (method **def local_act(self, state,exploration=1,add_noise=True)** in class DDPGAgent() in agent.py)\n",
    "    - the noise is progressively (muliply by a decay value) smoothed using the scalar exploration_eps\n",
    "\n",
    "- **Learning**:\n",
    "    - The learning is done  if t_step % self.config.ddpg_update_every (self.config.ddpg_update_every value is set to 2, so each odd number), this is done in the **def step(self,t_step)** metod in class MADDPGCoordinator() in coordinator.py )\n",
    "    - The learning is done muliple times for each agent using different sarsa tuples (**def step(self,t_step)** method in class MADDPGCoordinator() in coordinator.py )\n",
    "    - The learning (updated of the weights) is based on the [deterministic deep policy gradient](http://proceedings.mlr.press/v32/silver14.pdf) approach and it is done in **def learn(self, experiences, gamma)**,  in the class DDPGAgent() in agent.py.\n",
    "   - After updating the weights of the network a soft upated is applied between the actor and the critic (** def soft_update(self, local_model, target_model, tau)** in  class DDPGAgent() in agent.py.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networks descriptions\n",
    "\n",
    "- The env is returning a tuple (states,actions,next_states,rewards,dones), where each value of the tuple contains both the values for agent 1 and two, but *each agent is using only its related(state,action,next_state,reward,done)*\n",
    "\n",
    "- The structure of the **Actor network** (3 hidden layers) is the following:\n",
    "     - first hidden layer state_dimension * 128\n",
    "     - second hidden layer 128 * 64\n",
    "     - third hidden layer 128 * 2\n",
    "     - ReLu is used as non lineartiy\n",
    "     - tangh is used to keep the value in [-1,1]\n",
    "     - if the noise is added to the action, then I used the torch.clam(value,-1,1) to kee the value in [-1,1]\n",
    "        \n",
    "- The structure of the **Critic network** (3 hidden layers) is the following:\n",
    "     - first hidden layer state_dimension * 128\n",
    "     - second hidden layer 128 + 2(action) * 64\n",
    "     - third hidden layer 128 * 1\n",
    "     - ReLu is used as non lineartiy\n",
    "\n",
    "- All the networks are using a different ADAM optimizer instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What has been changed from the classic DDPG \n",
    "- The code is based on the DDPG algorithm with the following modification:\n",
    "     - **central cordinator**, there is a cordinator between the two angents, which has the role to send requests to the agents and to manage a central buffer \n",
    "     - **updating the networks** multiple times during one episode\n",
    "     - **repating the learning steps** multiple times after sampling the buffer\n",
    "     - **gradient clip** for critic has suggested in the course (torch.nn.utils.clip_grad_norm_(self.critic_local.parameters(), 1))\n",
    "     - **shared buffer/networks**, two agents share the same buffer/networks,stored in the cordinator. (this has been inspired by the following [github-repos](https://github.com/hortovanyi/DRLND-Collab-Compete)\n",
    "     - **agents share the same critic**, the two agents share the same critic. (this has been inspired by the following [github-repos](https://github.com/hortovanyi/DRLND-Collab-Compete)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scripts to Run \n",
    "\n",
    "- There are two main scripts in the main foler:\n",
    "    - main_script_ddpg_test.py, which is used to see the agents in action loading the weights of the networks that have been learned during the train\n",
    "    - main_script_ddpg_train.py, which is used to train the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example of output when you run the main_script_dq_train.py :\n",
    "\n",
    "```sh\n",
    "/Users/antonio.penta/Documents/virtualenv/drl_multiagent_rl/bin/python /Users/antonio.penta/Documents/workspace/python/deep_reinforcement_learning/drl_multiagent_rl/main_script_maddpg_train.py\n",
    "Mono path[0] = '/Users/antonio.penta/Documents/workspace/python/deep_reinforcement_learning/drl_multiagent_rl/env/Tennis.app/Contents/Resources/Data/Managed'\n",
    "Mono config path = '/Users/antonio.penta/Documents/workspace/python/deep_reinforcement_learning/drl_multiagent_rl/env/Tennis.app/Contents/MonoBleedingEdge/etc'\n",
    "INFO:unityagents:\n",
    "'Academy' started successfully!\n",
    "Unity Academy name: Academy\n",
    "        Number of Brains: 1\n",
    "        Number of External Brains : 1\n",
    "        Lesson number : 0\n",
    "        Reset Parameters :\n",
    "\t\t\n",
    "Unity brain name: TennisBrain\n",
    "        Number of Visual Observations (per agent): 0\n",
    "        Vector Observation space type: continuous\n",
    "        Vector Observation space size (per agent): 8\n",
    "        Number of stacked Vector Observation: 3\n",
    "        Vector Action space type: continuous\n",
    "        Vector Action space size (per agent): 2\n",
    "        Vector Action descriptions: , \n",
    "Number of agents: 2\n",
    "Size of each action: 2\n",
    "There are 2 agents. Each observes a state with length: 24\n",
    "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
    "  0.          0.          0.          0.          0.          0.\n",
    "  0.          0.          0.          0.         -6.65278625 -1.5\n",
    " -0.          0.          6.83172083  6.         -0.          0.        ]\n",
    "Episode 0\t Average Score : 0.0000\t Eps: 1.97 ,Length Episode   14\n",
    "Episode 50\t Average Score : 0.0000\t Eps: 0.9644 ,Length Episode   13\n",
    "Episode 100\t Average Score : 0.0028\t Eps: 0.4415 ,Length Episode   13\n",
    "Episode 150\t Average Score : 0.0294\t Eps: 0.1167 ,Length Episode   42\n",
    "Episode 200\t Average Score : 0.0876\t Eps: 0.05 ,Length Episode   29\n",
    "Episode 250\t Average Score : 0.1286\t Eps: 0.05 ,Length Episode   56\n",
    "Episode 300\t Average Score : 0.3924\t Eps: 0.05 ,Length Episode   90\n",
    "\n",
    "Environment solved in 212 episodes!\tAverage Score: 0.50\n",
    "\n",
    "Environment solved in 213 episodes!\t Best Average Score: 0.53\n",
    "\n",
    "Environment solved in 214 episodes!\t Best Average Score: 0.54\n",
    "\n",
    "Environment solved in 215 episodes!\t Best Average Score: 0.55\n",
    "\n",
    "Environment solved in 216 episodes!\t Best Average Score: 0.55\n",
    "\n",
    "Environment solved in 219 episodes!\t Best Average Score: 0.57\n",
    "\n",
    "Environment solved in 220 episodes!\t Best Average Score: 0.60\n",
    "\n",
    "Environment solved in 221 episodes!\t Best Average Score: 0.62\n",
    "\n",
    "Environment solved in 222 episodes!\t Best Average Score: 0.64\n",
    "\n",
    "Environment solved in 223 episodes!\t Best Average Score: 0.67\n",
    "\n",
    "Environment solved in 224 episodes!\t Best Average Score: 0.69\n",
    "\n",
    "Environment solved in 225 episodes!\t Best Average Score: 0.72\n",
    "\n",
    "Environment solved in 226 episodes!\t Best Average Score: 0.74\n",
    "\n",
    "Environment solved in 227 episodes!\t Best Average Score: 0.77\n",
    "\n",
    "Environment solved in 228 episodes!\t Best Average Score: 0.79\n",
    "\n",
    "Environment solved in 230 episodes!\t Best Average Score: 0.82\n",
    "\n",
    "Environment solved in 232 episodes!\t Best Average Score: 0.84\n",
    "\n",
    "Environment solved in 233 episodes!\t Best Average Score: 0.86\n",
    "\n",
    "Environment solved in 234 episodes!\t Best Average Score: 0.88\n",
    "\n",
    "Environment solved in 236 episodes!\t Best Average Score: 0.89\n",
    "\n",
    "Environment solved in 237 episodes!\t Best Average Score: 0.92\n",
    "\n",
    "Environment solved in 238 episodes!\t Best Average Score: 0.92\n",
    "\n",
    "Environment solved in 239 episodes!\t Best Average Score: 0.95\n",
    "\n",
    "Environment solved in 240 episodes!\t Best Average Score: 0.95\n",
    "\n",
    "Environment solved in 241 episodes!\t Best Average Score: 0.96\n",
    "\n",
    "Environment solved in 242 episodes!\t Best Average Score: 0.97\n",
    "\n",
    "Environment solved in 243 episodes!\t Best Average Score: 1.00\n",
    "\n",
    "Environment solved in 244 episodes!\t Best Average Score: 1.00\n",
    "\n",
    "Environment solved in 245 episodes!\t Best Average Score: 1.03\n",
    "\n",
    "Environment solved in 246 episodes!\t Best Average Score: 1.05\n",
    "\n",
    "Environment solved in 247 episodes!\t Best Average Score: 1.06\n",
    "\n",
    "Environment solved in 248 episodes!\t Best Average Score: 1.08\n",
    "\n",
    "Environment solved in 249 episodes!\t Best Average Score: 1.10\n",
    "Episode 350\t Average Score : 1.1187\t Eps: 0.05 ,Length Episode  597\n",
    "\n",
    "Environment solved in 250 episodes!\t Best Average Score: 1.12\n",
    "\n",
    "Environment solved in 251 episodes!\t Best Average Score: 1.13\n",
    "\n",
    "Environment solved in 252 episodes!\t Best Average Score: 1.15\n",
    "\n",
    "Environment solved in 253 episodes!\t Best Average Score: 1.15\n",
    "\n",
    "Environment solved in 254 episodes!\t Best Average Score: 1.16\n",
    "\n",
    "Environment solved in 255 episodes!\t Best Average Score: 1.17\n",
    "\n",
    "Environment solved in 256 episodes!\t Best Average Score: 1.17\n",
    "\n",
    "Environment solved in 257 episodes!\t Best Average Score: 1.19\n",
    "\n",
    "Environment solved in 258 episodes!\t Best Average Score: 1.19\n",
    "\n",
    "Environment solved in 259 episodes!\t Best Average Score: 1.20\n",
    "\n",
    "Environment solved in 260 episodes!\t Best Average Score: 1.21\n",
    "\n",
    "Environment solved in 261 episodes!\t Best Average Score: 1.21\n",
    "\n",
    "Environment solved in 263 episodes!\t Best Average Score: 1.21\n",
    "\n",
    "Environment solved in 264 episodes!\t Best Average Score: 1.21\n",
    "\n",
    "Environment solved in 265 episodes!\t Best Average Score: 1.22\n",
    "\n",
    "Environment solved in 266 episodes!\t Best Average Score: 1.23\n",
    "\n",
    "Environment solved in 267 episodes!\t Best Average Score: 1.25\n",
    "\n",
    "Environment solved in 268 episodes!\t Best Average Score: 1.27\n",
    "\n",
    "Environment solved in 269 episodes!\t Best Average Score: 1.29\n",
    "\n",
    "Environment solved in 270 episodes!\t Best Average Score: 1.32\n",
    "\n",
    "Environment solved in 271 episodes!\t Best Average Score: 1.34\n",
    "\n",
    "Environment solved in 277 episodes!\t Best Average Score: 1.34\n",
    "\n",
    "Environment solved in 278 episodes!\t Best Average Score: 1.35\n",
    "\n",
    "Environment solved in 279 episodes!\t Best Average Score: 1.35\n",
    "Episode 400\t Average Score : 1.1567\t Eps: 0.05 ,Length Episode   50\n",
    "Episode 450\t Average Score : 0.5243\t Eps: 0.05 ,Length Episode  137\n",
    "Episode 500\t Average Score : 0.3468\t Eps: 0.05 ,Length Episode   52\n",
    "Episode 550\t Average Score : 0.7016\t Eps: 0.05 ,Length Episode   63\n",
    "Episode 600\t Average Score : 0.8799\t Eps: 0.05 ,Length Episode  213\n",
    "Episode 650\t Average Score : 0.9384\t Eps: 0.05 ,Length Episode  218\n",
    "Episode 700\t Average Score : 0.8113\t Eps: 0.05 ,Length Episode   13\n",
    "Episode 750\t Average Score : 0.4514\t Eps: 0.05 ,Length Episode   89\n",
    "\n",
    "Process finished with exit code 0\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameters\n",
    "- All the HyperParameters are managed in the config class in the folder utils\n",
    "\n",
    "- I report here the summary :\n",
    "\n",
    "    - num_episodes = 800  # num_episodes (int): maximum number of training episodesor the score\n",
    "    - max_steps_4_episodes = 1000  # max_t (int) max length of the time stemps\n",
    "    - network_random_seed =0\n",
    "    - actor_fc1_units = 128  # number neurons first layer actor\n",
    "    - actor_fc2_units = 64 # number neurons second layer actor\n",
    "    - actor_fc3_units = 32  # number neurons first layer actor , not used\n",
    "    - critic_fc1_units = 128  # number neurons first layer critic\n",
    "    - critic_fc2_units = 64 # number neurons second layer critic\n",
    "    - critic_fc3_units= 32 # number neurons third layer critic, not used\n",
    "    - actor_non_linearity = F.relu # activation function used in the actor network\n",
    "    - critic_non_linearity = F.relu # activation function used in the critic network\n",
    "    - actor_lr = 1e-3 # learning rate of the actor\n",
    "    - critic_lr = 1e-3  # learning rate of the critic\n",
    "    - actor_weight_decay = 0.0  # L2 weight decay\n",
    "    - critic_weight_decay = 0.0  # L2 weight decay\n",
    "    - noise_seed =0 \n",
    "    - noise_mu = 0.\n",
    "    - noise_theta = 0.15\n",
    "    - noise_sigma =  0.2\n",
    "    - maddpa_buffer_size = int(1e5)  # replay buffer size\n",
    "    - maddpa_batch_size = 256  # minibatch size\n",
    "    - maddpa_buffer_random_seed = 24 # random seed buffer\n",
    "    - ddpg_updates_per_step = 4 # how many time run update\n",
    "    - ddpg_update_every = 2  # every n time step do update\n",
    "    - maddpa_gamma = 0.99  # discount factor\n",
    "    - maddpa_tau = 1e-2   # for soft update of target parameters\n",
    "    - exploration_epsilon_max = 2.0 # episilon used as start point for the exploration\n",
    "    - exploration_episilon_min = 0.05 # episilon used as minimum point for the exploration\n",
    "    - exploration_episilon_decay = 0.999 # episilon decay\n",
    "    - grad_normalization_critic = 0.5\n",
    "\n",
    "- The class used to stored all the parameters is reported below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import inspect\n",
    "from types import FunctionType\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "class Config():\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.version = 1  # version (int): version number to save model check point and files\n",
    "\n",
    "        self.log = False # log used to print instructions\n",
    "\n",
    "        self.time_stamp_report = 50  #log result within the espiside each time_stamp_report\n",
    "\n",
    "        self.num_episodes = 800  # num_episodes (int): maximum number of training episodes\n",
    "        self.max_score = 0.5  # max_score (float): that target score that we would like to reach, the benchmark is 15 in 1700 episode\n",
    "        self.score_window_size = 100  # score_window_size(int): buffer size for the score\n",
    "        self.max_steps_4_episodes = 1000  # max_t (int) max length of the time stemps\n",
    "\n",
    "\n",
    "        self.network_random_seed =0\n",
    "        self.actor_fc1_units = 128  # number neurons first layer actor\n",
    "        self.actor_fc2_units = 64 # number neurons second layer actor\n",
    "        self.actor_fc3_units = 32  # number neurons first layer actor , not used\n",
    "\n",
    "        self.critic_fc1_units = 128  # number neurons first layer critic\n",
    "        self.critic_fc2_units = 64 # number neurons second layer critic\n",
    "        self.critic_fc3_units= 32 # number neurons third layer critic, not used\n",
    "\n",
    "        self.critic_dropout_p = 0.5# not used\n",
    "\n",
    "        self.actor_non_linearity = F.relu # activation function used in the actor network\n",
    "        self.actor_non_linearity.__name__='relu'\n",
    "\n",
    "\n",
    "        self.critic_non_linearity = F.relu # activation function used in the critic network\n",
    "        self.critic_non_linearity.__name__ = 'relu'\n",
    "\n",
    "\n",
    "\n",
    "        self.actor_lr = 1e-3 # learning rate of the actor\n",
    "        self.critic_lr = 1e-3  # learning rate of the critic\n",
    "\n",
    "        self.actor_weight_decay = 0.0  # L2 weight decay\n",
    "        self.critic_weight_decay = 0.0  # L2 weight decay\n",
    "\n",
    "        # parameter for the noise\n",
    "        self.noise_seed =0 \n",
    "        self.noise_mu = 0.\n",
    "        self.noise_theta = 0.15\n",
    "        self.noise_sigma =  0.2\n",
    "\n",
    "\n",
    "\n",
    "        self.maddpa_buffer_size = int(1e5)  # replay buffer size\n",
    "        self.maddpa_batch_size = 256  # minibatch size\n",
    "        self.maddpa_buffer_random_seed = 24 # random seed buffer\n",
    "\n",
    "        self.ddpg_updates_per_step = 4 # how many time run update\n",
    "        self.ddpg_update_every = 2  # every n time step do update\n",
    "\n",
    "        self.maddpa_gamma = 0.99  # discount factor\n",
    "        self.maddpa_tau = 1e-2   # for soft update of target parameters\n",
    "\n",
    "        self.exploration_epsilon_max = 2.0 # episilon used as start point for the exploration\n",
    "        self.exploration_episilon_min = 0.05 # episilon used as minimum point for the exploration\n",
    "        self.exploration_episilon_decay = 0.999 # episilon decay\n",
    "\n",
    "\n",
    "        self.grad_normalization_actor = 1 # not used in the code\n",
    "        self.grad_normalization_critic = 0.5\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        status = {}\n",
    "        for x, y in self.__dict__.items():\n",
    "            if type(y) == FunctionType:\n",
    "                status[x] = getattr(self, x).__name__\n",
    "            else:\n",
    "                status[x] = str(getattr(self, x))\n",
    "        return json.dumps(status)\n",
    "\n",
    "\n",
    "    def getDict(self):\n",
    "        status = {}\n",
    "        for x, y in self.__dict__.items():\n",
    "            if type(y) == FunctionType:\n",
    "                status[x] = getattr(self, x).__name__\n",
    "            else:\n",
    "                status[x] = str(getattr(self, x))\n",
    "        return status\n",
    "\n",
    "    \n",
    "# from https://stackoverflow.com/questions/18873066/pretty-json-formatting-in-ipython-notebook    \n",
    "class RenderJSON(object):\n",
    "    def __init__(self, json_data):\n",
    "        if isinstance(json_data, dict):\n",
    "            self.json_str = json.dumps(json_data)\n",
    "        else:\n",
    "            self.json_str = json_data\n",
    "        self.uuid = str(uuid.uuid4())\n",
    "    def _ipython_display_(self):\n",
    "        display_html('<div id=\"{}\" style=\"height: 600px; width:100%;\"></div>'.format(self.uuid), raw=True)\n",
    "        display_javascript(\"\"\"\n",
    "        require([\"https://rawgit.com/caldwell/renderjson/master/renderjson.js\"], function() {\n",
    "        document.getElementById('%s').appendChild(renderjson(%s))\n",
    "        });\n",
    "        \"\"\" % (self.uuid, self.json_str), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"445893ef-8e83-4d78-86c4-59b508038c46\" style=\"height: 600px; width:100%;\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        require([\"https://rawgit.com/caldwell/renderjson/master/renderjson.js\"], function() {\n",
       "        document.getElementById('445893ef-8e83-4d78-86c4-59b508038c46').appendChild(renderjson({\"version\": \"1\", \"log\": \"False\", \"time_stamp_report\": \"50\", \"num_episodes\": \"800\", \"max_score\": \"0.5\", \"score_window_size\": \"100\", \"max_steps_4_episodes\": \"1000\", \"network_random_seed\": \"0\", \"actor_fc1_units\": \"128\", \"actor_fc2_units\": \"64\", \"actor_fc3_units\": \"32\", \"critic_fc1_units\": \"128\", \"critic_fc2_units\": \"64\", \"critic_fc3_units\": \"32\", \"critic_dropout_p\": \"0.5\", \"actor_non_linearity\": \"relu\", \"critic_non_linearity\": \"relu\", \"actor_lr\": \"0.001\", \"critic_lr\": \"0.001\", \"actor_weight_decay\": \"0.0\", \"critic_weight_decay\": \"0.0\", \"noise_seed\": \"0\", \"noise_mu\": \"0.0\", \"noise_theta\": \"0.15\", \"noise_sigma\": \"0.2\", \"maddpa_buffer_size\": \"100000\", \"maddpa_batch_size\": \"256\", \"maddpa_buffer_random_seed\": \"24\", \"ddpg_updates_per_step\": \"4\", \"ddpg_update_every\": \"2\", \"maddpa_gamma\": \"0.99\", \"maddpa_tau\": \"0.01\", \"exploration_epsilon_max\": \"2.0\", \"exploration_episilon_min\": \"0.05\", \"exploration_episilon_decay\": \"0.999\", \"grad_normalization_actor\": \"1\", \"grad_normalization_critic\": \"0.5\"}))\n",
       "        });\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_javascript, display_html, display\n",
    "config = Config()\n",
    "RenderJSON(str(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what works and what does not  (at least in my experiments)\n",
    "- *With the expression **does not work**, I mean that I did not see improvements compared to the results reported here, it could happen that by considering a long simulation some this attempt could lead to a best score, but to answer this question you need to pay a lot of money to Amazon :), to lunch and wait the experiments to finish.* \n",
    "\n",
    "- I observe a **good improvement** in the average score, if I use the **ReLU** activation in the critic instead of the **Leaky ReLU**\n",
    "- The **exploration** (the factor to scale the noise) should be greater that one and decrase by a decay factor in the first episode\n",
    "- 4 hidden layers **does not improved** the performances\n",
    "- batch normalization both in critic and actor **does not improved** the performances\n",
    "- The target and local both in critic and actor **need to be inilized with same weights**,the target could be to far from the local\n",
    "- I have used different kind of strategies for using the noise as exploration factor :\n",
    "    - Symmetric noise (randomly change the direction of the sign in the exploration) **does not work**\n",
    "    - Decay the **exploration** in each episode instead in each time stamp  **does not work**\n",
    "    - Decay the **exploration** lineary in a range **does not work**\n",
    "    - Increase the std in the noise **does not work**\n",
    "- **Ensure** to each episode last at least 1000, in order to collect more data for the buffer\n",
    "- **Avoid infinite loop** in the episode (while True), becouse in the last episodes the agents could play for ever\n",
    "-  The critic **needs to be shared** by the actors\n",
    "-  Having as input of the first layer of the critic the states+actions **does not work**, actions are considered as input in the second layer.\n",
    "- Updating the networks less often (now is done every odd numbers) **does not work**\n",
    "- Reducing the buffer size, ensuring to use only the new data, **does not work**\n",
    "- Considering as input of the critic both states (from agent 1 and 2) and  both actions (from agent 1 and 2) **does not work**\n",
    "- Having a shared instance of the noise generator **does not work**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "#i load only the first run scores, \n",
    "path_scores = 'data/scores_1.txt'\n",
    "rolling_window = 100\n",
    "with open(path_scores) as f:\n",
    "    array_scores = np.array([float(item) for item in f.readlines()])\n",
    "\n",
    "rolling_mean = pd.Series(array_scores).rolling(rolling_window).mean()\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(array_scores)), array_scores, label='full score')\n",
    "plt.plot(np.arange(len(rolling_mean)), rolling_mean, label='rolling mean window =100')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL\n",
    "- - The final model is stored in  the model folder :\n",
    "    - first_checkpoint_agent_1_version_1.pth (first model with Average Score of 0.50),\n",
    "    - first_checkpoint_agent_2_version_1.pth (first model with Average Score of 0.50),\n",
    "    - best_checkpoint_agent_1_version_1.pth (best model with Average Score of 1.35),\n",
    "    - best_checkpoint_agent_1_version_1.pth (best model with Average Score of 1.35),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video\n",
    "- Video with Agent in action : https://www.youtube.com/watch?v=jtyQqDcZgRs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future works:\n",
    "- The exploration eps can really change the performance, now the scale parameter is following a deterministic law (decay the value each time stamps), it will be interesting to use another the network to learn the best eps value given the context.\n",
    "- I have observed in the simulations that sometimes the actions are stacked in the same positions, it will be interesting to 6 outputs in the actor network, two related to the absolute values of each action and the other four to output the probability to select positive or negative direction for each action. In this case we can still use ReLu and separate the learning of force values from their directions.\n",
    "- Another approach for action exploration using [OpenAI approach](https://blog.openai.com/better-exploration-with-parameter-noise/) or noise netoworks as explanined [here](https://youtu.be/L6xaQ501jEs?t=3046)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "- https://github.com/hortovanyi/DRLND-Collab-Compete\n",
    "- https://github.com/RitwikSaikia/drlnd_p3_colab_compete\n",
    "- Slack channel of the course :https://drlnd.slack.com/messages/CBMKK16DR/convo/CBMNKQ6R0-1538937877.000100/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl_cont_control",
   "language": "python",
   "name": "drl_cont_control"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
